{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.multiprocessing\n",
    "\n",
    "from helpers.tools import *\n",
    "from helpers.tools import lagged_batch_corr\n",
    "from model.model_wrapper import Architecture_PL\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "# Loads all checkpoints in a given folder structure and calculates all necessary predictions. Also saves the according labels to be save."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For zero shot we test three things: \n",
    "\n",
    "- River Benchmark\n",
    "- Aerosol Benchmark\n",
    "\n",
    "Selected this here by hand because I am very lazy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc = torchmetrics.classification.BinaryAUROC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>HP</th>\n",
       "      <th>seed</th>\n",
       "      <th>hparams_search</th>\n",
       "      <th>model.optimizer_lr</th>\n",
       "      <th>data.batch_size</th>\n",
       "      <th>model.weight_decay</th>\n",
       "      <th>model.model_type</th>\n",
       "      <th>model.corr_regularization</th>\n",
       "      <th>corr_input</th>\n",
       "      <th>regression_head</th>\n",
       "      <th>data.ds_name</th>\n",
       "      <th>max_lags</th>\n",
       "      <th>n_vars</th>\n",
       "      <th>model</th>\n",
       "      <th>Test1_Auroc</th>\n",
       "      <th>Test1_MSE</th>\n",
       "      <th>Test2_AUROC</th>\n",
       "      <th>Test2_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43</td>\n",
       "      <td>std_runs_slurm.yaml</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>convM</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>joint</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>big.yaml</td>\n",
       "      <td>0.871109</td>\n",
       "      <td>0.03637622</td>\n",
       "      <td>0.89227587</td>\n",
       "      <td>0.03218321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.1</th>\n",
       "      <td>50</td>\n",
       "      <td>std_runs_slurm.yaml</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>transformer</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>joint</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>big.yaml</td>\n",
       "      <td>0.971022</td>\n",
       "      <td>0.012118887</td>\n",
       "      <td>0.97848606</td>\n",
       "      <td>0.009607594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.2</th>\n",
       "      <td>49</td>\n",
       "      <td>std_runs_slurm.yaml</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>bidirectional</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>joint</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>big.yaml</td>\n",
       "      <td>0.96785104</td>\n",
       "      <td>0.013725153</td>\n",
       "      <td>0.97649235</td>\n",
       "      <td>0.009861699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.3</th>\n",
       "      <td>42</td>\n",
       "      <td>std_runs_slurm.yaml</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>mlp</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>joint</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>big.yaml</td>\n",
       "      <td>0.791368</td>\n",
       "      <td>0.046149682</td>\n",
       "      <td>0.7982332</td>\n",
       "      <td>0.043174013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.4</th>\n",
       "      <td>50</td>\n",
       "      <td>std_runs_slurm.yaml</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>unidirectional</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>joint</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>big.yaml</td>\n",
       "      <td>0.96973234</td>\n",
       "      <td>0.013177577</td>\n",
       "      <td>0.9781359</td>\n",
       "      <td>0.009636639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "HP  seed       hparams_search model.optimizer_lr data.batch_size   \n",
       "6     43  std_runs_slurm.yaml              0.001              16  \\\n",
       "9.1   50  std_runs_slurm.yaml              0.001              64   \n",
       "7.2   49  std_runs_slurm.yaml              0.001              16   \n",
       "4.3   42  std_runs_slurm.yaml             0.0001              64   \n",
       "8.4   50  std_runs_slurm.yaml              0.001              64   \n",
       "\n",
       "HP  model.weight_decay model.model_type model.corr_regularization corr_input   \n",
       "6                 0.01            convM                      True       True  \\\n",
       "9.1                  0      transformer                     False       True   \n",
       "7.2               0.01    bidirectional                     False       True   \n",
       "4.3                  0              mlp                      True       True   \n",
       "8.4               0.01   unidirectional                     False       True   \n",
       "\n",
       "HP  regression_head data.ds_name max_lags n_vars     model Test1_Auroc   \n",
       "6             False        joint        3      5  big.yaml    0.871109  \\\n",
       "9.1           False        joint        3      5  big.yaml    0.971022   \n",
       "7.2           False        joint        3      5  big.yaml  0.96785104   \n",
       "4.3           False        joint        3      5  big.yaml    0.791368   \n",
       "8.4           False        joint        3      5  big.yaml  0.96973234   \n",
       "\n",
       "HP     Test1_MSE Test2_AUROC    Test2_MSE  \n",
       "6     0.03637622  0.89227587   0.03218321  \n",
       "9.1  0.012118887  0.97848606  0.009607594  \n",
       "7.2  0.013725153  0.97649235  0.009861699  \n",
       "4.3  0.046149682   0.7982332  0.043174013  \n",
       "8.4  0.013177577   0.9781359  0.009636639  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the best models: \n",
    "best = pd.read_csv(\"multirun/experiment_2_std_big/summary.csv\", index_col=0).T\n",
    "\n",
    "stack = []\n",
    "for x in best[\"model.model_type\"].unique():\n",
    "    stack.append(best.loc[best[\"model.model_type\"] == x].sort_values(\"Test1_Auroc\", ascending=False)[:1])\n",
    "\n",
    "pd.concat(stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = \"multirun/experiment_2_std_big/13-47-18/4/run/epoch=13-step=6902.ckpt\"\n",
    "uni = \"multirun/experiment_2_std_big/13-43-18/8/run/epoch=57-step=57130.ckpt\"\n",
    "bi= \"multirun/experiment_2_std_big/13-45-14/7/run/epoch=35-step=141768.ckpt\"\n",
    "conv = \"multirun/experiment_2_std_big/13-46-17/6/run/epoch=7-step=31504.ckpt\"\n",
    "trf = \"multirun/experiment_2_std_big/13-44-13/9/run/epoch=65-step=32538.ckpt\"\n",
    "best = [mlp, uni, bi, conv, trf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# River"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "data = load_river_data()\n",
    "# create proper padding\n",
    "a= torch.concat([data[0][0,:,:], torch.normal(0, 0.1, (len(data[0][0]),2))], axis=1)\n",
    "a = a.unsqueeze(0)\n",
    "corr = lagged_batch_corr(a,3)\n",
    "\n",
    "\n",
    "for x in best:\n",
    "    model = Architecture_PL.load_from_checkpoint(x)\n",
    "    M = model.model\n",
    "    M = M.to(\"cpu\")\n",
    "    M = M.eval()\n",
    "    pred = torch.sigmoid(M((a[:,:600,:], corr)))[0,:3,:3, -1]\n",
    "    res.append(auroc(pred, data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>tensor(0.4250)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uGRU</th>\n",
       "      <td>tensor(1.0000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bGRU</th>\n",
       "      <td>tensor(0.5000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CM</th>\n",
       "      <td>tensor(0.6000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trf</th>\n",
       "      <td>tensor(1.0000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "MLP   tensor(0.4250)\n",
       "uGRU  tensor(1.0000)\n",
       "bGRU  tensor(0.5000)\n",
       "CM    tensor(0.6000)\n",
       "Trf   tensor(1.0000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(res, index = [\"MLP\", \"uGRU\", \"bGRU\", \"CM\", \"Trf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(res, index = [\"MLP\", \"uGRU\", \"bGRU\", \"CM\", \"Trf\"]).to_csv(\"scores/zero_shot_rivers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kuramoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(\"data/deterministic_ds/kuramoto/simple_test.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.stack([x[0] for x in data])[:250]\n",
    "Y = torch.stack([x[1] for x in data])[:250]\n",
    "X = X - X.min() / (X.max() - X.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = lagged_batch_corr(X,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "cleaned_res = []\n",
    "for x in best:\n",
    "    model = Architecture_PL.load_from_checkpoint(x)\n",
    "    M = model.model\n",
    "    M = M.to(\"cpu\")\n",
    "    M = M.eval()\n",
    "    #pred = torch.sigmoid(M((X, corr)))[:,:,:,-1]\n",
    "    pred = torch.sigmoid(M((X, corr))).max(axis=3)[0]\n",
    "\n",
    "    res.append(auroc(pred, Y))\n",
    "    stack_pred_cleaned = []\n",
    "    stack_lab_cleaned = []\n",
    "    for x in pred:\n",
    "        stack_pred_cleaned.append(x.flatten()[~ torch.eye(5,5).flatten().bool()])\n",
    "    for x in Y:\n",
    "        stack_lab_cleaned.append(x.flatten()[~ torch.eye(5,5).flatten().bool()])\n",
    "    cleaned_res.append(auroc(torch.concat(stack_pred_cleaned), torch.concat(stack_lab_cleaned)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor(0.4665),\n",
       "  tensor(0.4403),\n",
       "  tensor(0.4183),\n",
       "  tensor(0.4230),\n",
       "  tensor(0.4227)],\n",
       " [tensor(0.5018),\n",
       "  tensor(0.5466),\n",
       "  tensor(0.4962),\n",
       "  tensor(0.5086),\n",
       "  tensor(0.5939)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res,cleaned_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5939)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auroc(torch.concat(stack_pred_cleaned), torch.concat(stack_lab_cleaned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aerosol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(\"data/deterministic_ds/aerosol/simple_test.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =data[0][:300]\n",
    "Y = data[1][:300]\n",
    "X = (X - X.min()) / (X.max() - X.min())\n",
    "corr = lagged_batch_corr(X,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m res \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mbest\u001b[49m:\n\u001b[1;32m      3\u001b[0m     model \u001b[38;5;241m=\u001b[39m Architecture_PL\u001b[38;5;241m.\u001b[39mload_from_checkpoint(x)\n\u001b[1;32m      4\u001b[0m     M \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best' is not defined"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for x in best:\n",
    "    model = Architecture_PL.load_from_checkpoint(x)\n",
    "    M = model.model\n",
    "    M = M.to(\"cpu\")\n",
    "    M = M.eval()\n",
    "    pred = torch.sigmoid(M((X, corr)))[:,:,:,-1]\n",
    "    #pred = torch.sigmoid(M((X, corr))).max(axis=3)[0]\n",
    "    res.append(pred[:,0,1] > pred[:,1,0])\n",
    "pd.DataFrame([(x.sum() / len(x)).numpy() for x in res], index = [\"MLP\", \"uGRU\", \"bGRU\", \"CM\", \"Trf\"]).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal_pretraining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
